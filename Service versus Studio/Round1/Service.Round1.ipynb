{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we can display multiple results without calling print :)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.17\n"
     ]
    }
   ],
   "source": [
    "# Check that azureml is available\n",
    "\n",
    "import azureml.core\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate if we haven't already\n",
    "\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "credentials = InteractiveLoginAuthentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the workspace info\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config(auth=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subscription_id': '<azure-subscription-id>',\n",
       " 'resource_group': '<myresourcegroup>',\n",
       " 'workspace_name': '<myworkspace>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by the way, config.json should look like this:\n",
    "{\n",
    "    \"subscription_id\": \"<azure-subscription-id>\",\n",
    "    \"resource_group\": \"<myresourcegroup>\",\n",
    "    \"workspace_name\": \"<myworkspace>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new experiment if we haven't already\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name='Round1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the experiment to run locally for simplicity reasons\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: Round1_1552921017_32a61559\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Running: ['python', 'azureml-setup/run_script.py', 'python', 'azureml-setup/context_manager_injector.py', '-i', 'ProjectPythonPath:context_managers.ProjectPythonPath', '-i', 'OutputCollection:context_managers.RunHistory', 'train.py']\n",
      "Logging experiment running status in history service.\n",
      "Streaming log file azureml-logs/80_driver_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Accuracy is 0.33182181915177383\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.20436406135559082 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: Round1_1552921017_32a61559\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'Round1_1552921017_32a61559',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-03-18T14:56:58.700925Z',\n",
       " 'endTimeUtc': '2019-03-18T14:58:11.326782Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '260a4dbb-91df-440f-bb21-f0f2a5590909'},\n",
       " 'runDefinition': {'Script': 'train.py',\n",
       "  'Arguments': [],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'local',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': True,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}]},\n",
       "    'BaseCondaEnvironment': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.2.2',\n",
       "    'Enabled': False,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://servicevsstudi6059947789.blob.core.windows.net/azureml/ExperimentRun/dcid.Round1_1552921017_32a61559/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=qw5iHutUZ90JBkqxdgThR%2FXq0oONY5fxHkZOvR71FNo%3D&st=2019-03-18T14%3A48%3A12Z&se=2019-03-18T22%3A58%3A12Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://servicevsstudi6059947789.blob.core.windows.net/azureml/ExperimentRun/dcid.Round1_1552921017_32a61559/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=PexIsEs7Qbzz4lerMfl2UhinQIGJlw8dMdYyJmWhcIU%3D&st=2019-03-18T14%3A48%3A12Z&se=2019-03-18T22%3A58%3A12Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://servicevsstudi6059947789.blob.core.windows.net/azureml/ExperimentRun/dcid.Round1_1552921017_32a61559/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=%2Bn%2F08W6UEbrtMeQ6%2FqmHOLmqq1JMIkTVPAhqPE7oqns%3D&st=2019-03-18T14%3A48%3A12Z&se=2019-03-18T22%3A58%3A12Z&sp=r'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actually run the experiment\n",
    "\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "config = ScriptRunConfig(source_directory='.',\n",
    "                         script='train.py',\n",
    "                         run_config=run_config)\n",
    "\n",
    "run = exp.submit(config)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.33182181915177383}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and then display the metrics logged during the run\n",
    "\n",
    "run.get_metrics()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
